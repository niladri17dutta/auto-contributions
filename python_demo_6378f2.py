
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ Generated by GitMaxer (Free Plan)
# ğŸ”— Upgrade at https://gitmaxer.vercel.app for watermark-free code
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Spectrogram Generator Tutorial: Visualizing Audio Frequencies

# Learning Objective:
# This tutorial will teach you how to generate and visualize a spectrogram
# from an audio file using Python. A spectrogram is a visual representation
# of the spectrum of frequencies of a signal as it varies with time.
# We'll focus on understanding how to:
# 1. Load an audio file.
# 2. Compute the Short-Time Fourier Transform (STFT) to analyze frequency content over time.
# 3. Convert the STFT results into a visually interpretable spectrogram.

# You'll need to install a few libraries if you haven't already:
# pip install numpy scipy matplotlib librosa

import numpy as np
from scipy.io import wavfile
import matplotlib.pyplot as plt
import librosa # A powerful library for audio analysis

def generate_spectrogram(audio_file_path, nfft=2048, hop_length=512):
    """
    Generates and displays a spectrogram for a given audio file.

    Args:
        audio_file_path (str): The path to the audio file (e.g., a .wav file).
        nfft (int): The size of the FFT window. Larger values provide better
                    frequency resolution but poorer time resolution.
                    Commonly set to a power of 2 (e.g., 1024, 2048).
        hop_length (int): The number of samples between successive FFT windows.
                          Smaller values lead to smoother spectrograms but
                          more data. It's often related to nfft (e.g., nfft/4 or nfft/2).
    """

    print(f"Loading audio file: {audio_file_path}")

    # 1. Load the audio file
    # librosa.load is a convenient function that handles various audio formats
    # and automatically resamples the audio to a consistent sample rate (22050 Hz by default).
    # y is the audio time series (a numpy array of amplitude values).
    # sr is the sampling rate of the audio.
    try:
        y, sr = librosa.load(audio_file_path)
        print(f"Audio loaded successfully. Sample rate: {sr} Hz, Duration: {len(y)/sr:.2f} seconds")
    except Exception as e:
        print(f"Error loading audio file: {e}")
        return

    # 2. Compute the Short-Time Fourier Transform (STFT)
    # The STFT breaks the audio signal into small, overlapping windows and
    # computes the Fourier Transform for each window. This allows us to see
    # how the frequency content changes over time.
    # D is a 2D numpy array where:
    # - Rows represent frequency bins.
    # - Columns represent time frames.
    # - Values are complex numbers representing the magnitude and phase of each frequency at each time.
    print("Computing STFT...")
    D = librosa.stft(y, n_fft=nfft, hop_length=hop_length)
    print(f"STFT computed. Shape: {D.shape}")

    # 3. Convert STFT to a visually interpretable spectrogram
    # We typically visualize the magnitude (amplitude) of the STFT, often on a
    # logarithmic scale (decibels) for better visibility of quieter sounds.
    # np.abs(D) gives us the magnitude of the complex STFT results.
    # librosa.amplitude_to_db converts these magnitudes to decibels (dB).
    # ref=np.max ensures that the loudest part of the signal is set to 0 dB.
    magnitude_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)
    print("Converted STFT to dB scale.")

    # 4. Visualize the spectrogram
    print("Generating spectrogram plot...")
    plt.figure(figsize=(12, 6)) # Set the figure size for better readability

    # Display the spectrogram using imshow.
    # - magnitude_db: The 2D array of dB values to display.
    # - origin='lower': Places the 0 Hz frequency at the bottom of the plot.
    # - aspect='auto': Adjusts the aspect ratio of the plot.
    # - cmap='viridis': A common and perceptually uniform colormap.
    plt.imshow(magnitude_db, origin='lower', aspect='auto', cmap='viridis')

    # Add labels and title for clarity
    plt.xlabel("Time (frames)")
    plt.ylabel("Frequency (Hz)")
    plt.title("Spectrogram of Audio Signal")

    # Add a color bar to indicate the dB scale
    plt.colorbar(format='%+2.0f dB')

    # Calculate and display time and frequency ticks more intuitively
    # Time axis: We know the hop_length and the number of frames.
    # Each frame represents hop_length samples, so the time is frame_index * hop_length / sr
    frames = np.arange(magnitude_db.shape[1])
    times = librosa.frames_to_time(frames, sr=sr, hop_length=hop_length)
    plt.xticks(np.linspace(0, magnitude_db.shape[1] - 1, 10), [f'{t:.2f}' for t in np.linspace(times[0], times[-1], 10)])
    plt.xlabel("Time (s)")

    # Frequency axis: The STFT produces nfft/2 + 1 frequency bins.
    # The maximum frequency represented is sr/2 (Nyquist frequency).
    max_freq = sr / 2
    freq_bins = np.arange(magnitude_db.shape[0])
    plt.yticks(np.linspace(0, magnitude_db.shape[0] - 1, 10), [f'{f:.0f}' for f in np.linspace(0, max_freq, 10)])
    plt.ylabel("Frequency (Hz)")


    plt.tight_layout() # Adjust layout to prevent labels overlapping
    plt.show() # Display the plot
    print("Spectrogram generated and displayed.")

# --- Example Usage ---
# To run this example, you'll need an audio file (e.g., a .wav file).
# If you don't have one, you can record a short snippet.
# For demonstration purposes, let's assume you have a file named 'my_audio.wav'
# in the same directory as your script.

# Example 1: Using a dummy audio file path (replace with your actual file)
# try:
#     generate_spectrogram('my_audio.wav')
# except FileNotFoundError:
#     print("\n--- Example Usage Error ---")
#     print("Please replace 'my_audio.wav' with the path to your actual audio file.")
#     print("You can download sample audio files or record your own.")
#     print("For instance, download 'trumpet.wav' from a reliable source and use its path.")
#     print("---------------------------\n")

# Example 2: Generating a short sine wave and visualizing it (requires no external file)
# This is a good way to test the code without needing an audio file beforehand.
print("\n--- Generating and visualizing a test sine wave ---")
sr_test = 22050 # Sample rate for the test signal
duration_test = 3 # seconds
frequency_test = 440 # Hz (A4 note)

# Generate time vector
t_test = np.linspace(0., duration_test, int(sr_test * duration_test))

# Generate sine wave
# Using np.sin(2 * np.pi * frequency_test * t_test) creates the wave.
# We then save this as a WAV file to use our generate_spectrogram function.
amplitude_test = np.iinfo(np.int16).max * 0.5 # Scale to avoid clipping
y_test = amplitude_test * np.sin(2 * np.pi * frequency_test * t_test)

# Convert to 16-bit integers, a common format for WAV files
y_test_int = y_test.astype(np.int16)

# Save the generated sine wave to a temporary WAV file
test_audio_filename = "test_sine_wave.wav"
try:
    wavfile.write(test_audio_filename, sr_test, y_test_int)
    print(f"Test sine wave saved as '{test_audio_filename}'")

    # Now, generate the spectrogram for this temporary file
    generate_spectrogram(test_audio_filename, nfft=1024, hop_length=256) # Using smaller nfft for better time resolution

except Exception as e:
    print(f"Error during test sine wave generation or saving: {e}")

# Clean up the temporary file (optional)
import os
if os.path.exists(test_audio_filename):
    # os.remove(test_audio_filename) # Uncomment to automatically delete the file after running
    print(f"Test file '{test_audio_filename}' created. You can delete it manually.")
print("--- Test sine wave visualization complete ---")